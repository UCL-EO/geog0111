{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt='UCL' src=\"images/ucl_logo.png\" align='center'>\n",
    "\n",
    "\n",
    "[<img src=\"images/noun_post_2109127.svg\" width=\"50\" align='right'>](023_Plotting.ipynb)\n",
    "[<img src=\"images/noun_pre_2109128.svg\" width=\"50\" align='right'>](021_Streams.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 022 OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "### Purpose\n",
    "\n",
    "In the previous sessions, we used [`pathlib`](https://docs.python.org/3/library/pathlib.html) and [`urlpath`](https://github.com/chrono-meter/urlpath) to access files and do basic reading and writing operations. \n",
    "\n",
    "Often we need to apply an interpreter to the data we access. This might be text formats such as [`json`](https://docs.python.org/3/library/json.html) or [`yaml`](https://python.land/data-processing/python-yaml) that we have already seen. Or they might be more complex binary formats such as we use for geospatial data. We have come across MODIS files in `hdf` format, for instance. \n",
    "\n",
    "In this session, we will extend this to deal with reading and writing such geospatial files.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "You will need some understanding of the following:\n",
    "\n",
    "\n",
    "* [001 Using Notebooks](001_Notebook_use.ipynb)\n",
    "* [002 Unix](002_Unix.ipynb) with a good familiarity with the UNIX commands we have been through.\n",
    "* [003 Getting help](003_Help.ipynb)\n",
    "* [010 Variables, comments and print()](010_Python_Introduction.ipynb)\n",
    "* [011 Data types](011_Python_data_types.ipynb) \n",
    "* [012 String formatting](012_Python_strings.ipynb)\n",
    "* [013_Python_string_methods](013_Python_string_methods.ipynb)\n",
    "* [020_Python_files](020_Python_files.ipynb)\n",
    "\n",
    "You will need to recall details from [020_Python_files](020_Python_files.ipynb) and [021_URLs](021_URLs.ipynb).\n",
    "\n",
    "### Test\n",
    "\n",
    "You should run a [NASA account test](004_Accounts.ipynb) if you have not already done so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have read:\n",
      "\n",
      "It is easy for humans to read and write.\n",
      "It is easy for machines to parse and generate. \n",
      "\n",
      "lines list:\n",
      "['', 'It is easy for humans to read and write.', 'It is easy for machines to parse and generate. ', '']\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# Using `Path.read_text()` read the text from the \n",
    "# file `work/easy.txt` and print the text returned.\n",
    "\n",
    "text = Path('work/easy.txt').read_text()\n",
    "print(f'I have read:\\n{text}')\n",
    "\n",
    "# split the text into lines of text using `str.split()` \n",
    "# at each newline, and print out the resulting list\n",
    "text_list = text.split('\\n')\n",
    "print(f'lines list:\\n{text_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MODIS\n",
    "\n",
    "We have previously come across MODIS data and how to download it to the local system. Let's look deeper into these datasets now.\n",
    "\n",
    "As a start on this, let's first access a MODIS file from the web, as we did in [021_URLs](021_URLs.ipynb). We will use [`modisFile`](geog0111/modisUtils.py) to access the MODIS files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/plewis/.modis_cache/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.05/MCD15A3H.A2020005.h08v06.006.2020010210940.hdf\n"
     ]
    }
   ],
   "source": [
    "from geog0111.modisUtils import modisFile\n",
    "# settings\n",
    "\n",
    "modinfo = {  \n",
    "    'product'  : 'MCD15A3H',\n",
    "    'year'     : 2020,\n",
    "    'month'    : 1,\n",
    "    'day'      : 5,\n",
    "    'tile'     : 'h08v06'\n",
    "}\n",
    "\n",
    "filename = modisFile(year, month, day,tile,verbose=False)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "\n",
    "# BETTER ANSWER\n",
    "# write a function called `get_locals` that loops \n",
    "# over each entry in the list `hdf_urls` and returns the local filename \n",
    "def get_locals(hdf_urls):\n",
    "    '''\n",
    "    get the cached filenames for the URL list\n",
    "    '''\n",
    "    return [f.local() for f in hdf_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.01/MCD15A3H.A2020001.h08v06.006.2020006032951.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.05/MCD15A3H.A2020005.h08v06.006.2020010210940.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.09/MCD15A3H.A2020009.h08v06.006.2020014204616.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.13/MCD15A3H.A2020013.h08v06.006.2020018030252.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.17/MCD15A3H.A2020017.h08v06.006.2020022034013.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.21/MCD15A3H.A2020021.h08v06.006.2020026032135.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.25/MCD15A3H.A2020025.h08v06.006.2020030025757.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.29/MCD15A3H.A2020029.h08v06.006.2020034165001.hdf.store')]\n"
     ]
    }
   ],
   "source": [
    "# write code to test the function and print results \n",
    "# using data from modis.get_url(\"2020\",\"01\",\"*\")\n",
    "kwargs = {\n",
    "    'product'    : 'MCD15A3H',\n",
    "    'db_dir'     : 'work',\n",
    "    'local_dir'  : 'work',\n",
    "}\n",
    "modis = Modis(**kwargs)\n",
    "# get URLs\n",
    "hdf_urls = modis.get_url(year=\"2020\",month=\"01\",day=\"*\")\n",
    "# test\n",
    "print(get_locals(hdf_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `gdal`\n",
    "\n",
    "\n",
    "The MODIS files are in `hdf` format, and as we have noted, we do not generally want direct access to the raw (byte) information. Instead we must use some package to interpret the data. \n",
    "\n",
    "We can use the package [`gdal`](https://gdal.org/python/) to access information from these and other geospatial files. We will explore the contents of MODIS files in a later session, but for now, we can note that each MODIS file contains a set of sub datasets.\n",
    "\n",
    "Basic use of `gdal` in this context is:\n",
    "\n",
    "    g = gdal.Open(filename.as_posix())\n",
    "    \n",
    "where `filename.as_posix()` is a string of the filename we want open the file in `gdal`. If this returns None, there has been a problem opening the file, so we might check that.\n",
    "\n",
    "Then\n",
    "\n",
    "    g.GetSubDatasets()\n",
    "   \n",
    "returns a list of sub-dataset information. Each item in the list is a tuple of two strings. In each, the first is the full name of the sub-dataset, and the second a text descriptor of the dataset. We call these `filename,name` below.\n",
    "\n",
    "We read the dataset with:\n",
    "\n",
    "    gsub = gdal.Open(filename)\n",
    "    data = gsub.ReadAsArray()\n",
    "    \n",
    "In the illustration below, we will examine only the first sub-dataset `g.GetSubDatasets()[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset info is: [2400x2400] Fpar_500m MOD_Grid_MCD15A3H (8-bit unsigned integer)\n",
      "dataset read is shape (2400, 2400) and type <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "from geog0111.modisUtils import modisFile\n",
    "# settings\n",
    "\n",
    "modinfo = {  \n",
    "    'product'  : 'MCD15A3H',\n",
    "    'year'     : 2020,\n",
    "    'month'    : 1,\n",
    "    'day'      : 5,\n",
    "    'tile'     : 'h08v06'\n",
    "}\n",
    "\n",
    "filename = modisFile(year, month, day,tile,verbose=False)\n",
    "\n",
    "if filename:\n",
    "# open the local file associated with the dataset\n",
    "    g = gdal.Open(filename.as_posix())\n",
    "    if g:\n",
    "        # get the first SDS only for illustration\n",
    "        filename,name = g.GetSubDatasets()[0]\n",
    "        print(f'dataset info is: {name}')\n",
    "        # read the dataset\n",
    "        gsub = gdal.Open(filename)\n",
    "        if gsub:\n",
    "            data = gsub.ReadAsArray()\n",
    "        print(f'dataset read is shape {data.shape} and type {type(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 1\n",
    "\n",
    "    name = '[2400x2400] Fpar_500m MOD_Grid_MCD15A3H (8-bit unsigned integer)'\n",
    "\n",
    "* Take the string variable `name` above, split it to obtain the second field (`Fpar_500m` here) and store this in a variable `sds_name`\n",
    "* Write a function called `get_data` that reads an HDF (MODIS) filename, and returns a dictionary of all of the sub-datasets in the file, using `ReadAsArray()`. The dictionary keys should correspond to the items in  `sds_name` above.\n",
    "* test the code by showing the keys in the dictionary returned and the shape of their dataset\n",
    "\n",
    "You will need to recall how to split a string, that was covered in [013 Python string methods](013_Python_string_methods.ipynb#split()-and-join()). You will also need to recall how to [loop over a dictionary](016_Python_for.ipynb#looping-over-dictionaries,-and-assert). We saw how to find the shape of the dataset returned above (`.shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fpar_500m\n"
     ]
    }
   ],
   "source": [
    "# ANSWER \n",
    "name = '[2400x2400] Fpar_500m MOD_Grid_MCD15A3H (8-bit unsigned integer)'\n",
    "\n",
    "# Take the string variable name above, split it to obtain the \n",
    "# second field (Fpar_500m here) and store this in a variable sds_name\n",
    "\n",
    "# use str.split() and take item 1 from the list\n",
    "sds_name = name.split()[1]\n",
    "print(sds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Write a function called get_data that reads an HDF (MODIS) filename, \n",
    "# and returns a dictionary of all of the data in the file,\n",
    "# using ReadAsArray(). \n",
    "# The dictionary keys should correspond to the items in sds_name above.\n",
    "\n",
    "def get_data(hdf_filename):\n",
    "    '''\n",
    "    reads an HDF (MODIS) filename \n",
    "    and return a dictionary of all of the sub-datasets in the file,\n",
    "    '''\n",
    "    # open file\n",
    "    g = gdal.Open(hdf_filename)\n",
    "    # initialise dictionary\n",
    "    odict = {}\n",
    "    # return empty-handed\n",
    "    if g == None:\n",
    "        return odict\n",
    "    for filename,name in g.GetSubDatasets():\n",
    "        sds_name = name.split()[1]\n",
    "        data = gdal.Open(filename).ReadAsArray()\n",
    "        odict[sds_name] = data\n",
    "    return odict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fpar_500m           : (2400, 2400)\n",
      "Lai_500m            : (2400, 2400)\n",
      "FparLai_QC          : (2400, 2400)\n",
      "FparExtra_QC        : (2400, 2400)\n",
      "FparStdDev_500m     : (2400, 2400)\n",
      "LaiStdDev_500m      : (2400, 2400)\n"
     ]
    }
   ],
   "source": [
    "# test the code by showing the keys in the dictionary \n",
    "# returned and the shape of their dataset\n",
    "import gdal\n",
    "from  geog0111.modis import Modis\n",
    "\n",
    "# as before\n",
    "kwargs = {\n",
    "    'product'    : 'MCD15A3H',\n",
    "    'db_dir'     : 'work',\n",
    "    'local_dir'  : 'work',\n",
    "}\n",
    "modis = Modis(**kwargs)\n",
    "url = modis.get_url(year=\"2020\",month=\"01\",day=\"01\")[0]\n",
    "\n",
    "hdf_filename = str(url.local())\n",
    "\n",
    "# test the code\n",
    "hdf_dict = get_data(hdf_filename)\n",
    "\n",
    "# loop over dictionary items\n",
    "for k,v in hdf_dict.items():\n",
    "    # do some neat formatting on k\n",
    "    print(f'{k:<20s}: {v.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we have used `Path` and `URL` classes to read and write text and binary files. We have combined these ideas with earlier work to access MODIS datafiles and other text and binary datasets. For data we access through a URL, we can do file operations on a cached version of the file. We have refreshed our memory of some of the earlier material, especially string formatting.\n",
    "\n",
    "We have learned how to use `gdal` to look at the sub-datasets in an HDF file and also how to read them.\n",
    "\n",
    "You should now have some confidence in these matters, so that if you were set a task of downloading and saving datasets, as well as other tasks such as finding their size, whether the exists or not, you could do this. \n",
    "\n",
    "Remember:\n",
    "\n",
    "Modis library\n",
    "\n",
    "            from  geog0111.modis import Modis\n",
    "            modis = Modis(**kwargs)\n",
    "            \n",
    "\n",
    "            get_url(**kwargs) method of geog0111.modis.Modis instance\n",
    "                Get URL object list for NASA MODIS products\n",
    "                for the specified product, tile, year, month, day\n",
    "\n",
    "                Keyword Arguments:\n",
    "\n",
    "                verbose:  bool\n",
    "                product : str e.g. 'MCD15A3H'\n",
    "                tile    : str e.g. 'h08v06'\n",
    "                year    : str valid 2000-present\n",
    "                month   : str 01-12\n",
    "                day     : str 01-(28,29,30,31)\n",
    "\n",
    "`gdal`\n",
    "\n",
    "| Command | Comment |\n",
    "|---|---|\n",
    "|`g = gdal.Open(filename)` | Open geospatial file `filename` and return `gdal` object `g` (`None` if file not opened correctly)|\n",
    "|`g.GetSubDatasets()` | Get list of sub-datasets from `gdal` object `g`| \n",
    "|`g.ReadAsArray()` | Read dataset from `gdal` object `g` into array |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[<img src=\"images/noun_post_2109127.svg\" width=\"50\" align='right'>](023_Plotting.ipynb)\n",
    "[<img src=\"images/noun_pre_2109128.svg\" width=\"50\" align='right'>](021_Streams.ipynb)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env:geog0111-geog0111",
   "language": "python",
   "name": "conda-env-geog0111-geog0111-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
