{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt='UCL' src=\"images/ucl_logo.png\" align='center'>\n",
    "\n",
    "\n",
    "[<img src=\"images/noun_post_2109127.svg\" width=\"50\" align='right'>](016_Python_for.ipynb)\n",
    "[<img src=\"images/noun_pre_2109128.svg\" width=\"50\" align='right'>](018_Python_xxx.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 022 Read and Write: URLs and files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "### Purpose\n",
    "\n",
    "In the previous session, we used [`pathlib`](https://docs.python.org/3/library/pathlib.html) and the local package [gurlpath](geog0111/gurlpath) derived from [`urlpath`](https://github.com/chrono-meter/urlpath) to open object streams from URLs and files. \n",
    "\n",
    "In this session, we will extend this to deal with reading and writing to text and binary files and URLs.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "You will need some understanding of the following:\n",
    "\n",
    "\n",
    "* [001 Using Notebooks](001_Notebook_use.ipynb)\n",
    "* [002 Unix](002_Unix.ipynb) with a good familiarity with the UNIX commands we have been through.\n",
    "* [003 Getting help](003_Help.ipynb)\n",
    "* [010 Variables, comments and print()](010_Python_Introduction.ipynb)\n",
    "* [011 Data types](011_Python_data_types.ipynb) \n",
    "* [012 String formatting](012_Python_strings.ipynb)\n",
    "* [013_Python_string_methods](013_Python_string_methods.ipynb)\n",
    "* [020_Python_files](020_Python_files.ipynb)\n",
    "\n",
    "You will need to recall details from [020_Python_files](020_Python_files.ipynb) on using the two packages.\n",
    "\n",
    "### Test\n",
    "\n",
    "You should run a [NASA account test](notebooks/004_Accounts.ipynb#Test) if you have not already done so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing\n",
    "\n",
    "As before, we note that we can conveniently use `pathlib` to deal with file input and output. The main methods we have seen are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|command|  purpose|\n",
    "|---|---|\n",
    "|`Path.open()`| open a file and return a file descriptor|\n",
    "|`Path.read_text()`|  read text|\n",
    "|`Path.write_text()`| write text|\n",
    "|`Path.read_bytes()`| read byte data|\n",
    "|`Path.write_bytes()`| write byte data|\n",
    "\n",
    "\n",
    "For `gurlpath` we have the following equivalent functions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|command|  purpose|\n",
    "|---|---|\n",
    "|`URL.open()`| open a file descriptor with data from a URL|\n",
    "|`URL.read_text()`|  read text from URL|\n",
    "|`URL.write_text()`| write text to file|\n",
    "|`URL.read_bytes()`| read byte data from URL|\n",
    "|`URL.write_bytes()`| write byte data to file|\n",
    "\n",
    "Recall that the `write` functions (and `open` when used for write) write to local files, not to the URL. They have a keyword argument `local_file` to set the location to write the file to. If this is not given, the the directory structure of the URL is used (relative to the current directory). Alternatively, you can set the keyword `local_dir`, or set `URL.local_file` or `URL.local_dir` as appropriate. \n",
    "\n",
    "Note that `URL` is tolerant of calling with a `Path`: if we call `URL` with a local file, most operations will continue and apply the appropriate `Path` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read and write text\n",
    "\n",
    "We can read text from a file with `Path.read_text()` or from a URL with `URL.read_text()`, then either `Path.write_text()` or  `URL.write_text()` to write text to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 90 bytes to work/easy.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# from https://www.json.org\n",
    "some_text = '''\n",
    "It is easy for humans to read and write.\n",
    "It is easy for machines to parse and generate. \n",
    "'''\n",
    "\n",
    "# set up the filename\n",
    "outfile = Path('work/easy.txt')\n",
    "# write the text\n",
    "nbytes = outfile.write_text(some_text)\n",
    "# print what we did\n",
    "print(f'wrote {nbytes} bytes to {outfile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 1\n",
    "\n",
    "* Using `Path.read_text()` read the text from the file `work/easy.txt` and print the text returned.\n",
    "* split the text into lines of text using `str.split()` at each newline, and print out the resulting list\n",
    "\n",
    "You learned how to split strings in [013_Python_string_methods](013_Python_string_methods.ipynb#split()-and-join())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have read:\n",
      "\n",
      "It is easy for humans to read and write.\n",
      "It is easy for machines to parse and generate. \n",
      "\n",
      "lines list:\n",
      "['', 'It is easy for humans to read and write.', 'It is easy for machines to parse and generate. ', '']\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# Using `Path.read_text()` read the text from the \n",
    "# file `work/easy.txt` and print the text returned.\n",
    "\n",
    "text = Path('work/easy.txt').read_text()\n",
    "print(f'I have read:\\n{text}')\n",
    "\n",
    "# split the text into lines of text using `str.split()` \n",
    "# at each newline, and print out the resulting list\n",
    "text_list = text.split('\\n')\n",
    "print(f'lines list:\\n{text_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show that we get the same result reading the same file locally from [`data/json-en.html`](data/json-en.html) or from the web from [`https://www.json.org/json-en.html`](https://www.json.org/json-en.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> reading db file /Users/plewis/.url_db/.db.yml\n",
      "--> updated cache database in /Users/plewis/.url_db/.db.yml\n",
      "--> db file [PosixPath('/Users/plewis/.url_db/.db.yml')]\n",
      "--> trying https://www.json.org/json-en.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files are the same\n"
     ]
    }
   ],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "from pathlib import Path\n",
    "\n",
    "# first read the data from URL with no cache\n",
    "# and directory work\n",
    "u = 'https://www.json.org/json-en.html'\n",
    "url = URL(u,local_dir='work',verbose=True,noclobber=False)\n",
    "data_url = url.read_text()\n",
    "\n",
    "# then from file in directory data\n",
    "data_file = Path('data/json-en.html').read_text()\n",
    "\n",
    "assert data_url == data_file\n",
    "print('files are the same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read and write binary data\n",
    "\n",
    "We can read binary data from a file with `Path.read_bytes()` or from a URL with `URL.read_bytes()`, then either `Path.write_bytes()` or  `URL.write_bytes()` to write the binary data to a file. Other than that, and the fact that we cannot directly visualise the contents of the binary files without some interpreted code, there is no real difference in how we treat them.\n",
    "\n",
    "Let's first access a MODIS file from the web, as we did in [020_Python_files](020_Python_files.ipynb). Here, the `kwargs` are passed on to `URL`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> reading db file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/.db.yml\n",
      "--> updated cache database in /Users/plewis/Documents/GitHub/geog0111/notebooks/work/.db.yml\n",
      "--> db file [PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/.db.yml')]\n",
      "--> retrieving glob https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.01/*.h08v06*.hdf from database\n"
     ]
    }
   ],
   "source": [
    "from  geog0111.modis import Modis\n",
    "\n",
    "kwargs = {\n",
    "    'verbose'    : True,\n",
    "    'db_dir'     : 'work',\n",
    "    'local_dir'  : 'work',\n",
    "}\n",
    "\n",
    "modis = Modis('MCD15A3H',**kwargs)\n",
    "url = modis.get_url(\"2020\",\"01\",\"01\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then read the data. Cached data will be used where available unless we set `noclobber=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data for https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.01/MCD15A3H.A2020001.h08v06.006.2020006032951.hdf cached in /Users/plewis/Documents/GitHub/geog0111/notebooks/work/MCD15A3H.A2020001.h08v06.006.2020006032951.hdf\n"
     ]
    }
   ],
   "source": [
    "b  = url.read_bytes()\n",
    "print(f'data for {url} cached in {url.local()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could explicitly write the data to a file, but since we are using a cache, there is no real point. This means that we can just use the URL to access the dataset. If we do need to specify the filename explicitly for any other codes, we can use `url.local()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 2\n",
    "\n",
    "Using the code:\n",
    "    \n",
    "    from  geog0111.modis import Modis\n",
    "    \n",
    "    kwargs = {\n",
    "        'verbose'    : True,\n",
    "        'db_dir'     : 'work',\n",
    "        'local_dir'  : 'work',\n",
    "    }\n",
    "\n",
    "    modis = Modis('MCD15A3H',**kwargs)\n",
    "    # get URLs\n",
    "    hdf_urls = modis.get_url(\"2020\",\"01\",\"01\")\n",
    "\n",
    "* write a function called `get_locals` that loops over each entry in the list `hdf_urls` and returns the local filename \n",
    "* write code to test the function and print results using data from `modis.get_url(\"2020\",\"01\",\"*\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "\n",
    "# ANSWER\n",
    "# write a function called `get_locals` that loops \n",
    "# over each entry in the list `hdf_urls` and returns the local filename \n",
    "def get_locals(hdf_urls):\n",
    "    '''\n",
    "    get the cached filenames for the URL list\n",
    "    '''\n",
    "    olist = []\n",
    "    for f in hdf_urls:\n",
    "        olist.append([f.local()])\n",
    "    return olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "\n",
    "# BETTER ANSWER\n",
    "# write a function called `get_locals` that loops \n",
    "# over each entry in the list `hdf_urls` and returns the local filename \n",
    "def get_locals(hdf_urls):\n",
    "    '''\n",
    "    get the cached filenames for the URL list\n",
    "    '''\n",
    "    return [f.local() for f in hdf_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/MCD15A3H.A2020001.h08v06.006.2020006032951.hdf'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/MCD15A3H.A2020005.h08v06.006.2020010210940.hdf'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/MCD15A3H.A2020009.h08v06.006.2020014204616.hdf'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/MCD15A3H.A2020013.h08v06.006.2020018030252.hdf'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/MCD15A3H.A2020017.h08v06.006.2020022034013.hdf'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/MCD15A3H.A2020021.h08v06.006.2020026032135.hdf'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/MCD15A3H.A2020025.h08v06.006.2020030025757.hdf'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/MCD15A3H.A2020029.h08v06.006.2020034165001.hdf')]\n"
     ]
    }
   ],
   "source": [
    "# write code to test the function and print results \n",
    "# using data from modis.get_url(\"2020\",\"01\",\"*\")\n",
    "kwargs = {\n",
    "    'db_dir'     : 'work',\n",
    "    'local_dir'  : 'work',\n",
    "}\n",
    "\n",
    "modis = Modis('MCD15A3H',**kwargs)\n",
    "# get URLs\n",
    "hdf_urls = modis.get_url(\"2020\",\"01\",\"*\")\n",
    "# test\n",
    "print(get_locals(hdf_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 3\n",
    "\n",
    "* print out the absolute pathname of the directory that the binary file [`images/ucl.png`](images/ucl.png) is in\n",
    "* print the size of the file in kilobytes (KB) to two decimal places without reading the datafile. \n",
    "* read the datafile, and check you get the same data size\n",
    "\n",
    "You will need to recall how to find a file size in bytes using `Path`. This was covered in [020_Python_files](020_Python_files.ipynb). You will need to know how many bytes are in a KB. To print to two decimal places, you need to recall the string formatting we did in [012_Python_strings](012_Python_strings.ipynb#String-formating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/plewis/Documents/GitHub/geog0111/notebooks/images/ucl.png\n",
      "the file ucl.png is in /Users/plewis/Documents/GitHub/geog0111/notebooks/images\n",
      "ucl.png has size 1956 bytes\n",
      "ucl.png has size 1.91 KB\n",
      "the size of data read is 1956 bytes ->  1.91 KB\n"
     ]
    }
   ],
   "source": [
    "# ANSWER \n",
    "\n",
    "# print out the absolute pathname of the \n",
    "# directory that images/ucl.png is in\n",
    "abs_name = Path('images/ucl.png').absolute()\n",
    "print(abs_name)\n",
    "\n",
    "# we want the parent!\n",
    "print(f'the file {abs_name.name} is in {abs_name.parent}')\n",
    "\n",
    "# print the size of the file in bytes without reading the datafile. \n",
    "print(f'{abs_name.name} has size {abs_name.stat().st_size} bytes')\n",
    "\n",
    "# 1 KB is 1024 Bytes\n",
    "# .2f is 2 d.p. format\n",
    "print(f'{abs_name.name} has size ' +\\\n",
    "      f'{abs_name.stat().st_size/1024:.2f} KB')\n",
    "\n",
    "# read the datafile, and check you get the same data size\n",
    "dataset = abs_name.read_bytes()\n",
    "# size\n",
    "s = len(dataset)\n",
    "print(f'the size of data read is {s} bytes -> {s/1024 : .2f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we have used `Path` and `URL` classes to read and write text and binary files. We have combined these ideas with earlier work to access MODIS datafiles and other text and binary datasets. For data we access through a URL, we can do file operations on a cached version of the file. We have refreshed our memory of some of the earlier material, especially string formatting.\n",
    "\n",
    "You should now have some confidence in these matters, so that if you were set a task of downloading and saving datasets, as well as other tasks such as finding their size, whether the exists or not, you could do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[<img src=\"images/noun_post_2109127.svg\" width=\"50\" align='right'>](016_Python_for.ipynb)\n",
    "[<img src=\"images/noun_pre_2109128.svg\" width=\"50\" align='right'>](014_Python_groups.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
