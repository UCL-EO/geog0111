{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f40a8c",
   "metadata": {},
   "source": [
    "# 021 URLs : Answers to exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "* create a `URL` object for the file `table.html` in the directory `psd/enso/mei/` on the site `http://www.esrl.noaa.gov/`.\n",
    "* print out the url name and check it is `table.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.esrl.noaa.gov/psd/enso/mei/table.html\n",
      "passed\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "\n",
    "# create a URL object for the file table.html \n",
    "# in the directory psd/enso/mei/ on the site \n",
    "# http://www.esrl.noaa.gov/.\n",
    "\n",
    "site = 'http://www.esrl.noaa.gov/'\n",
    "site_dir = 'psd/enso/mei'\n",
    "site_file = 'table.html'\n",
    "url = URL(site,site_dir,site_file)\n",
    "\n",
    "# print out the url and check it is table.html\n",
    "print(url)\n",
    "assert url.name == site_file\n",
    "print('passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "* Use the `URL.get()` method to pull data from `https://covid.ourworldindata.org/data/ecdc/archived/full_data.csv` and store in a file called `work/full_data.csv`.\n",
    "* check the file size\n",
    "* show the first few lines of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work/full_data.csv size: 3215657 bytes\n",
      "0: date,location,new_cases,new_deaths,total_cases,total_deaths,weekly_cases,weekly_deaths,biweekly_cases,biweekly_deaths\n",
      "1: 2019-12-31,Afghanistan,0,0,,,,,,\n",
      "2: 2020-01-01,Afghanistan,0,0,,,,,,\n",
      "3: 2020-01-02,Afghanistan,0,0,,,,,,\n",
      "4: 2020-01-03,Afghanistan,0,0,,,,,,\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from urlpath import URL\n",
    "# ANSWER\n",
    "\n",
    "# Use the URL.get() method to pull data from \n",
    "# https://covid.ourworldindata.org/data/ecdc/full_data.csv \n",
    "# and store in a file called work/full_data.csv\n",
    "\n",
    "# set up URL object\n",
    "url = URL('https://covid.ourworldindata.org/data/archived/ecdc/full_data.csv')\n",
    "# set up file for data as Path\n",
    "ofile = Path('work',url.name)\n",
    "\n",
    "# get data \n",
    "r = url.get()\n",
    "# check response:\n",
    "if r.status_code == 200:\n",
    "    # ok\n",
    "    data = r.text\n",
    "    # remember how to write to a file from \n",
    "    # previous session on Path\n",
    "    ofile.write_text(data)\n",
    "    # check the file size\n",
    "    print(f'{ofile} size: {ofile.stat().st_size} bytes')\n",
    "    # show the first few lines of data\n",
    "    # NB data is a big long string, so split it on \\n\n",
    "    # into lines\n",
    "    data_lines = data.split('\\n')\n",
    "    for i in range(5):\n",
    "        print(f'{i}: {data_lines[i]}')\n",
    "else:\n",
    "    print(f'failed to pull data from {url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "* pull the MODIS dataset `MCD15A3H` for 9 January 2019 for tile `h08v06` and confirm that the dataset size is 8.5 MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor: https://e4ftl01.cr.usgs.gov\n",
      "-> https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.09/MCD15A3H.A2020009.h08v06.006.2020014204616.hdf\n",
      "getting MODIS URL\n",
      "MOTA/MCD15A3H.006/2020.01.09/MCD15A3H.A2020009.h08v06.006.2020014204616.hdf\n",
      "getting Auth\n",
      "response: 200\n",
      "file work/MCD15A3H.A2020009.h08v06.006.2020014204616.hdf written: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "from geog0111.modisUtils import modisURL\n",
    "from geog0111.cylog import Cylog\n",
    "from urlpath import URL\n",
    "from pathlib import Path\n",
    "# ANSWER\n",
    "\n",
    "# set up control for which MODIS product/date/tile\n",
    "\n",
    "modinfo = {  \n",
    "    'product'  : 'MCD15A3H',\n",
    "    'year'     : 2020,\n",
    "    'month'    : 1,\n",
    "    'day'      : 9,\n",
    "    'tile'     : 'h08v06'\n",
    "}\n",
    "\n",
    "# get the URL\n",
    "url = modisURL(**modinfo,verbose=False)\n",
    "if url:\n",
    "    print(f'anchor: {url.anchor}')\n",
    "    print(f'-> {url}')\n",
    "\n",
    "    # use url.anchor to get server name for Cylog\n",
    "    # add the username and password\n",
    "    print('getting MODIS URL')\n",
    "    username,password = Cylog(url.anchor).login()\n",
    "    url = url.with_userinfo(username,password)\n",
    "    # dont print out the username and password!\n",
    "    print('/'.join(url.parts[1:]))\n",
    "\n",
    "    # first call to URL to get auth\n",
    "    print('getting Auth')\n",
    "    r = url.get()\n",
    "    url2 = URL(r.url).with_userinfo(username,password)\n",
    "\n",
    "    if url2:\n",
    "    # net call to get data\n",
    "        r2 = url2.get()\n",
    "        print(f'response: {r2.status_code}')\n",
    "\n",
    "        if r2.status_code == 200:\n",
    "\n",
    "            # setup Path object for output file\n",
    "            filename = Path('work',url.name)\n",
    "\n",
    "            # write binary data\n",
    "            filename.write_bytes(r2.content)\n",
    "\n",
    "            # check size:\n",
    "            size_MB = filename.stat().st_size/(1024**2)\n",
    "\n",
    "            # report\n",
    "            print(f'file {filename} written: {size_MB :.1f} MB')\n",
    "        else:\n",
    "            print(f'{\"/\".join(url.parts[1:])} status code {r2.status_code}')\n",
    "    else:\n",
    "        print('error getting url')\n",
    "else:\n",
    "    print('error in data request')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "\n",
    "* pull the MODIS dataset `MCD15A3H` for 13 January 2019 for tile `h08v06` using `modisFile` and confirm that the dataset size is 8.5 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /Users/plewis/Documents/GitHub/geog0111/notebooks/.modis_cache/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.13/MCD15A3H.A2020013.h08v06.006.2020018030252.hdf is: 8.4 MB\n"
     ]
    }
   ],
   "source": [
    "from geog0111.modisUtils import modisFile\n",
    "\n",
    "# set up control for which MODIS product/date/tile\n",
    "\n",
    "modinfo = {  \n",
    "    'product'  : 'MCD15A3H',\n",
    "    'year'     : 2020,\n",
    "    'month'    : 1,\n",
    "    'day'      : 13,\n",
    "    'tile'     : 'h08v06'\n",
    "}\n",
    "\n",
    "filename = modisFile(**modinfo,verbose=False)\n",
    "\n",
    "if filename:\n",
    "    size_MB = filename.stat().st_size/(1024**2)\n",
    "    \n",
    "    # report\n",
    "    print(f'file {filename} is: {size_MB :.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "\n",
    "    name = '[2400x2400] Fpar_500m MOD_Grid_MCD15A3H (8-bit unsigned integer)'\n",
    "\n",
    "* Take the string variable `name` above, split it to obtain the second field (`Fpar_500m` here) and store this in a variable `sds_name`\n",
    "* Write a function called `getModisTiledata` that reads an HDF (MODIS) filename, and returns a dictionary of all of the sub-datasets in the file, using `ReadAsArray()`. The dictionary keys should correspond to the items in  `sds_name` above.\n",
    "* test the code by showing the keys in the dictionary returned and the shape of their dataset\n",
    "\n",
    "You will need to recall how to split a string, that was covered in [013 Python string methods](013_Python_string_methods.ipynb#split()-and-join()). You will also need to recall how to [loop over a dictionary](016_Python_for.ipynb#looping-over-dictionaries,-and-assert). We saw how to find the shape of the dataset returned above (`.shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fpar_500m\n"
     ]
    }
   ],
   "source": [
    "# ANSWER \n",
    "name = '[2400x2400] Fpar_500m MOD_Grid_MCD15A3H (8-bit unsigned integer)'\n",
    "\n",
    "# Take the string variable name above, split it to obtain the \n",
    "# second field (Fpar_500m here) and store this in a variable sds_name\n",
    "\n",
    "# use str.split() and take item 1 from the list\n",
    "sds_name = name.split()[1]\n",
    "print(sds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fpar_500m Lai_500m FparLai_QC FparExtra_QC FparStdDev_500m LaiStdDev_500m\n"
     ]
    }
   ],
   "source": [
    "# ANSWER \n",
    "from osgeo import gdal\n",
    "from geog0111.modisUtils import modisFile\n",
    "\n",
    "# set up control for which MODIS product/date/tile\n",
    "\n",
    "modinfo = {  \n",
    "    'product'  : 'MCD15A3H',\n",
    "    'year'     : 2020,\n",
    "    'month'    : 1,\n",
    "    'day'      : 13,\n",
    "    'tile'     : 'h08v06'\n",
    "}\n",
    "\n",
    "\n",
    "def getModisTiledata(**modinfo):\n",
    "    '''\n",
    "    get MODIS data dictionary\n",
    "    '''\n",
    "    # set up blank dictionary for output\n",
    "    odata = {}\n",
    "    filename = modisFile(**modinfo)\n",
    "    # error checking\n",
    "    if not filename:\n",
    "        return odata\n",
    "    g = gdal.Open(filename.as_posix())\n",
    "    if g:\n",
    "        for filename,name in g.GetSubDatasets():\n",
    "            # get the SDS\n",
    "            #print(f'dataset info is: {name}')\n",
    "            # read the dataset\n",
    "            gsub = gdal.Open(filename)\n",
    "            if gsub:\n",
    "                data = gsub.ReadAsArray()\n",
    "                sds_name = name.split()[1]\n",
    "                # load into dictionary\n",
    "                odata[sds_name] = data\n",
    "    return odata\n",
    "    \n",
    "data = getModisTiledata(**modinfo)\n",
    "print(*data.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env:geog0111-geog0111",
   "language": "python",
   "name": "conda-env-geog0111-geog0111-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
