{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 022 OLD : Answers to exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have read:\n",
      "\n",
      "It is easy for humans to read and write.\n",
      "It is easy for machines to parse and generate. \n",
      "\n",
      "lines list:\n",
      "['', 'It is easy for humans to read and write.', 'It is easy for machines to parse and generate. ', '']\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# Using `Path.read_text()` read the text from the \n",
    "# file `work/easy.txt` and print the text returned.\n",
    "\n",
    "text = Path('work/easy.txt').read_text()\n",
    "print(f'I have read:\\n{text}')\n",
    "\n",
    "# split the text into lines of text using `str.split()` \n",
    "# at each newline, and print out the resulting list\n",
    "text_list = text.split('\\n')\n",
    "print(f'lines list:\\n{text_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "\n",
    "# BETTER ANSWER\n",
    "# write a function called `get_locals` that loops \n",
    "# over each entry in the list `hdf_urls` and returns the local filename \n",
    "def get_locals(hdf_urls):\n",
    "    '''\n",
    "    get the cached filenames for the URL list\n",
    "    '''\n",
    "    return [f.local() for f in hdf_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.01/MCD15A3H.A2020001.h08v06.006.2020006032951.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.05/MCD15A3H.A2020005.h08v06.006.2020010210940.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.09/MCD15A3H.A2020009.h08v06.006.2020014204616.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.13/MCD15A3H.A2020013.h08v06.006.2020018030252.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.17/MCD15A3H.A2020017.h08v06.006.2020022034013.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.21/MCD15A3H.A2020021.h08v06.006.2020026032135.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.25/MCD15A3H.A2020025.h08v06.006.2020030025757.hdf.store'), PosixPath('/Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.29/MCD15A3H.A2020029.h08v06.006.2020034165001.hdf.store')]\n"
     ]
    }
   ],
   "source": [
    "# write code to test the function and print results \n",
    "# using data from modis.get_url(\"2020\",\"01\",\"*\")\n",
    "kwargs = {\n",
    "    'product'    : 'MCD15A3H',\n",
    "    'db_dir'     : 'work',\n",
    "    'local_dir'  : 'work',\n",
    "}\n",
    "modis = Modis(**kwargs)\n",
    "# get URLs\n",
    "hdf_urls = modis.get_url(year=\"2020\",month=\"01\",day=\"*\")\n",
    "# test\n",
    "print(get_locals(hdf_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "    name = '[2400x2400] Fpar_500m MOD_Grid_MCD15A3H (8-bit unsigned integer)'\n",
    "\n",
    "* Take the string variable `name` above, split it to obtain the second field (`Fpar_500m` here) and store this in a variable `sds_name`\n",
    "* Write a function called `get_data` that reads an HDF (MODIS) filename, and returns a dictionary of all of the sub-datasets in the file, using `ReadAsArray()`. The dictionary keys should correspond to the items in  `sds_name` above.\n",
    "* test the code by showing the keys in the dictionary returned and the shape of their dataset\n",
    "\n",
    "You will need to recall how to split a string, that was covered in [013 Python string methods](013_Python_string_methods.ipynb#split()-and-join()). You will also need to recall how to [loop over a dictionary](016_Python_for.ipynb#looping-over-dictionaries,-and-assert). We saw how to find the shape of the dataset returned above (`.shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fpar_500m\n"
     ]
    }
   ],
   "source": [
    "# ANSWER \n",
    "name = '[2400x2400] Fpar_500m MOD_Grid_MCD15A3H (8-bit unsigned integer)'\n",
    "\n",
    "# Take the string variable name above, split it to obtain the \n",
    "# second field (Fpar_500m here) and store this in a variable sds_name\n",
    "\n",
    "# use str.split() and take item 1 from the list\n",
    "sds_name = name.split()[1]\n",
    "print(sds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function called get_data that reads an HDF (MODIS) filename, \n",
    "# and returns a dictionary of all of the data in the file,\n",
    "# using ReadAsArray(). \n",
    "# The dictionary keys should correspond to the items in sds_name above.\n",
    "\n",
    "def get_data(hdf_filename):\n",
    "    '''\n",
    "    reads an HDF (MODIS) filename \n",
    "    and return a dictionary of all of the sub-datasets in the file,\n",
    "    '''\n",
    "    # open file\n",
    "    g = gdal.Open(hdf_filename)\n",
    "    # initialise dictionary\n",
    "    odict = {}\n",
    "    # return empty-handed\n",
    "    if g == None:\n",
    "        return odict\n",
    "    for filename,name in g.GetSubDatasets():\n",
    "        sds_name = name.split()[1]\n",
    "        data = gdal.Open(filename).ReadAsArray()\n",
    "        odict[sds_name] = data\n",
    "    return odict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fpar_500m           : (2400, 2400)\n",
      "Lai_500m            : (2400, 2400)\n",
      "FparLai_QC          : (2400, 2400)\n",
      "FparExtra_QC        : (2400, 2400)\n",
      "FparStdDev_500m     : (2400, 2400)\n",
      "LaiStdDev_500m      : (2400, 2400)\n"
     ]
    }
   ],
   "source": [
    "# test the code by showing the keys in the dictionary \n",
    "# returned and the shape of their dataset\n",
    "import gdal\n",
    "from  geog0111.modis import Modis\n",
    "\n",
    "# as before\n",
    "kwargs = {\n",
    "    'product'    : 'MCD15A3H',\n",
    "    'db_dir'     : 'work',\n",
    "    'local_dir'  : 'work',\n",
    "}\n",
    "modis = Modis(**kwargs)\n",
    "url = modis.get_url(year=\"2020\",month=\"01\",day=\"01\")[0]\n",
    "\n",
    "hdf_filename = str(url.local())\n",
    "\n",
    "# test the code\n",
    "hdf_dict = get_data(hdf_filename)\n",
    "\n",
    "# loop over dictionary items\n",
    "for k,v in hdf_dict.items():\n",
    "    # do some neat formatting on k\n",
    "    print(f'{k:<20s}: {v.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env:geog0111-geog0111",
   "language": "python",
   "name": "conda-env-geog0111-geog0111-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
