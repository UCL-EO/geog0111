{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 020 Files and other Resources : Answers to exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "There is a file called `environment.yml` in the directory `copy`.\n",
    "\n",
    "* use `Path` to generate the a variable `copy_dir` containing the pathname of the `copy` directory\n",
    "* create a variable `env_file` which adds add the file `environment.yml` to this \n",
    "* check to see if the file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does copy/environment.yml exist? True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# ANSWER\n",
    "\n",
    "# There is a file called environment.yml in the directory copy.\n",
    "# use Path to generate the a variable copy_dir containing the \n",
    "# pathname of the copy directory\n",
    "copy_dir = Path('copy')\n",
    "\n",
    "# create a variable env_file which adds add the file \n",
    "# environment.yml to this\n",
    "env_file = copy_dir / 'environment.yml'\n",
    "# or\n",
    "env_file = Path(copy_dir,'environment.yml')\n",
    "\n",
    "# check to see if the file exists\n",
    "print(f'does {env_file} exist? {env_file.exists()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "* Use `Path` to show the file permissions of all files that end `.sh` in the directory `bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin/notebook-mkdocs.sh    : 0o100755\n",
      "bin/notebook-run.sh       : 0o100755\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# use glob to get a list of filenames in the directory bin \n",
    "# that end with .sh -> pattern n* using a wildcard\n",
    "filenames = Path('bin').glob('n*')\n",
    "\n",
    "# loop over the filenames and print the permissions\n",
    "# as octal. Note how we use :25s to line items up\n",
    "for f in filenames:\n",
    "    print(f'{str(f):25s} : {oct(f.stat().st_mode)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin/notebook-mkdocs.sh\n",
      "bin/setup.sh\n",
      "bin/notebook-run.sh\n",
      "bin/fixA.sh\n",
      "bin/link-set.sh\n",
      "bin/clean0111.sh\n",
      "bin/tidy.sh\n",
      "bin/init.sh\n",
      "bin/sort-db.sh\n",
      "bin/get-datasets.sh\n",
      "bin/init0111.sh\n",
      "bin/set-course.sh\n",
      "bin/howmany.sh\n",
      "bin/shellMe.sh\n",
      "bin/database.sh\n",
      "bin/git-remove-all.sh\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# Use Path to show the file permissions of\n",
    "# all files that end .sh in the directory bin\n",
    "\n",
    "# use glob to get a list of filenames in the directory bin \n",
    "# that end with .sh -> pattern *.sh using a wildcard\n",
    "filenames = Path('bin').glob('*.sh')\n",
    "# loop over the filenames\n",
    "for f in filenames:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "\n",
    "* print out the absolute pathname of the directory that `images/ucl.png` is in\n",
    "* check that the file exists\n",
    "* if it does, print the size of the file in KB to two decimal places\n",
    "\n",
    "You will need to know how many Bytes in a Kilobyte, and how to [format a string to two decimal places](012_Python_strings.ipynb#String-formating). You will also need to remember how to use [`if` statements](015_Python_control.ipynb#Comparison-Operators-and-if)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory ucl.png is in is: /Users/plewis/Documents/GitHub/geog0111/notebooks/images\n",
      "file size 1956 Bytes ->  1.91 KB\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "\n",
    "# print out the absolute pathname of the \n",
    "# directory that images/ucl.png is in\n",
    "ucl = Path('images','ucl.png')\n",
    "\n",
    "# use absolute and parent\n",
    "# Use name to show how that is helpful\n",
    "print(f'The directory {ucl.name} is in is: {ucl.absolute().parent}')\n",
    "\n",
    "# check that the file exists\n",
    "# if it does ...\n",
    "if ucl.exists():\n",
    "    # print the size of the file in KB to two decimal places\n",
    "\n",
    "    # from above, use stat().st_size\n",
    "    size_in_bytes = ucl.stat().st_size\n",
    "    # 1024 Bytes -> 1 KB\n",
    "    size_in_KB = size_in_bytes/1024\n",
    "    # 2 dp -> : .2f\n",
    "    print(f'file size {size_in_bytes} Bytes -> {size_in_KB : .2f} KB')\n",
    "else:\n",
    "    print(f'file does not exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "\n",
    "* create a `URL` object for the file `table.html` in the directory `psd/enso/mei/` on the site `http://www.esrl.noaa.gov/`.\n",
    "* print out the url and check it is `table.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.esrl.noaa.gov/psd/enso/mei/table.html\n",
      "passed\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "\n",
    "# create a URL object for the file table.html \n",
    "# in the directory psd/enso/mei/ on the site \n",
    "# http://www.esrl.noaa.gov/.\n",
    "\n",
    "site = 'http://www.esrl.noaa.gov/'\n",
    "site_dir = 'psd/enso/mei'\n",
    "site_file = 'table.html'\n",
    "url = URL(site,site_dir,site_file)\n",
    "\n",
    "# print out the url and check it is table.html\n",
    "print(url)\n",
    "assert url.name == site_file\n",
    "print('passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5\n",
    "\n",
    "based on the code from above:\n",
    "\n",
    "    # settings\n",
    "    product = 'MCD15A3H'\n",
    "    year, month, day = '2020', '06', '01'\n",
    "    tile = 'h08v06'\n",
    "\n",
    "    # url with wildcards\n",
    "    site = 'https://e4ftl01.cr.usgs.gov'\n",
    "    site_dir = f'MOTA/{product}.006/{year}.{month}.{day}'\n",
    "    site_file = f'*.{tile}*.hdf'\n",
    "\n",
    "    # get the information\n",
    "    url = URL(site,site_dir,verbose=True)\n",
    "    hdf_urls = list(url.glob(site_file))[0]\n",
    "    \n",
    " * write a function called `modis_dataset` with arguments corresponding to the settings above\n",
    " * the function should return the URL objects of the NASA datasets specified by your arguments\n",
    " * your function should be fully documented and include some error checks\n",
    " * run a test of your function, and print the file size in MB for the file pointed to in the URL to 2 decimal places\n",
    " * what happens if you use a wildcard for the date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "\n",
    "# ANSWER 1\n",
    "\n",
    "# write a function called `modis_dataset` \n",
    "# with arguments corresponding to the settings above\n",
    "#\n",
    "# the function should return the URL objects of \n",
    "# the NASA datasets specified by your arguments\n",
    "#\n",
    "def modis_dataset(product, tile, year, month, day,\n",
    "                  verbose=False,\n",
    "                  site='https://e4ftl01.cr.usgs.gov'):\n",
    "    '''\n",
    "    Get URL object list for NASA MODIS products\n",
    "    for the specified product, tile, year, month, day\n",
    "    \n",
    "    Positional Arguments:\n",
    "     \n",
    "    product : str e.g. 'MCD15A3H'\n",
    "    tile    : str e.g. 'h08v06'\n",
    "    year    : str valid 2000-present\n",
    "    month   : str 01-12\n",
    "    day     : str 01-(28,29,30,31)\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    \n",
    "    site     =  'https://e4ftl01.cr.usgs.gov'\n",
    "    verbose  =  False\n",
    "    '''\n",
    "    # you should put some tests in\n",
    "    site_dir = f'MOTA/{product}.006/{year}.{month}.{day}'\n",
    "\n",
    "    site_file = f'*.{tile}*.hdf'\n",
    "\n",
    "    url = URL(site,site_dir,verbose=verbose)\n",
    "    hdf_urls = url.glob(site_file)\n",
    "    return hdf_urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov.store\n",
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern MOTA in https://e4ftl01.cr.usgs.gov/\n",
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA.store\n",
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern MCD15A3H.006 in https://e4ftl01.cr.usgs.gov/MOTA\n",
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006.store\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: 1 MB = 1024 * 1024 Bytes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern 2020.06.01 in https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006\n",
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.06.01.store\n",
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern *.h08v06*.hdf in https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.06.01\n",
      "--> trying https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.06.01/MCD15A3H.A2020153.h08v06.006.2020160231732.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.06.01/MCD15A3H.A2020153.h08v06.006.2020160231732.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> code 401\n",
      "--> getting login\n",
      "--> logging in to https://e4ftl01.cr.usgs.gov/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCD15A3H.A2020153.h08v06.006.2020160231732.hdf :  9.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> data read from https://e4ftl01.cr.usgs.gov/\n",
      "--> code 200\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 2\n",
    "# run a test of your function, \n",
    "# and print the file size in MB \n",
    "# for the file pointed to in the URL\n",
    "# to 2 decimal places\n",
    "\n",
    "msg = '''\n",
    "Note: 1 MB = 1024 * 1024 Bytes\n",
    "'''\n",
    "print(msg)\n",
    "\n",
    "args = ['MCD15A3H','h08v06','2020','06', '01']\n",
    "hdf_urls = modis_dataset(*args,verbose=True)\n",
    "# test if exist\n",
    "for u in hdf_urls:\n",
    "    print(u)\n",
    "    print(f'{u.name} : {u.stat().st_size/(1024*1024): .2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov.store\n",
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern MOTA in https://e4ftl01.cr.usgs.gov/\n",
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA.store\n",
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern MCD15A3H.006 in https://e4ftl01.cr.usgs.gov/MOTA\n",
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006.store\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: 1 MB = 1024 * 1024 Bytes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> parsing URLs from html file 4 items\n",
      "--> discovered 4 files with pattern 2020.*.01 in https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006\n",
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.01.store\n",
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern *.h08v06*.hdf in https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.01\n",
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.03.01.store\n",
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern *.h08v06*.hdf in https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.03.01\n",
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.06.01.store\n",
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern *.h08v06*.hdf in https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.06.01\n",
      "--> keeping existing file /Users/plewis/Documents/GitHub/geog0111/notebooks/work/e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.09.01.store\n",
      "--> parsing URLs from html file 1 items\n",
      "--> discovered 1 files with pattern *.h08v06*.hdf in https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.09.01\n",
      "--> trying https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.01/MCD15A3H.A2020001.h08v06.006.2020006032951.hdf\n",
      "--> code 401\n",
      "--> getting login\n",
      "--> logging in to https://e4ftl01.cr.usgs.gov/\n",
      "--> data read from https://e4ftl01.cr.usgs.gov/\n",
      "--> code 200\n",
      "--> trying https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.03.01/MCD15A3H.A2020061.h08v06.006.2020066032716.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCD15A3H.A2020001.h08v06.006.2020006032951.hdf :  8.65 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> code 401\n",
      "--> getting login\n",
      "--> logging in to https://e4ftl01.cr.usgs.gov/\n",
      "--> data read from https://e4ftl01.cr.usgs.gov/\n",
      "--> code 200\n",
      "--> trying https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.06.01/MCD15A3H.A2020153.h08v06.006.2020160231732.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCD15A3H.A2020061.h08v06.006.2020066032716.hdf :  8.63 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> code 401\n",
      "--> getting login\n",
      "--> logging in to https://e4ftl01.cr.usgs.gov/\n",
      "--> data read from https://e4ftl01.cr.usgs.gov/\n",
      "--> code 200\n",
      "--> trying https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.09.01/MCD15A3H.A2020245.h08v06.006.2020253152835.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCD15A3H.A2020153.h08v06.006.2020160231732.hdf :  9.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> code 401\n",
      "--> getting login\n",
      "--> logging in to https://e4ftl01.cr.usgs.gov/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCD15A3H.A2020245.h08v06.006.2020253152835.hdf :  10.46 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> data read from https://e4ftl01.cr.usgs.gov/\n",
      "--> code 200\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 3\n",
    "# what happens if you use a wildcard for the date?\n",
    "msg = '''\n",
    "Note: 1 MB = 1024 * 1024 Bytes\n",
    "'''\n",
    "print(msg)\n",
    "\n",
    "args = ['MCD15A3H','h08v06','2020','*', '01']\n",
    "hdf_urls = modis_dataset(*args,verbose=True)\n",
    "# test if exist\n",
    "for u in hdf_urls:\n",
    "    print(f'{u.name} : {u.stat().st_size/(1024*1024): .2f} MB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env:geog0111-geog0111",
   "language": "python",
   "name": "conda-env-geog0111-geog0111-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
